---
title: "Databricks Connect"
output: html_notebook
---

```{r setup}
# Packages ----
library(dplyr)
library(sparklyr)
library(ggplot2)

# Set env variables ----
Sys.setenv(SPARK_HOME = "/Users/jamesblair/anaconda3/envs/databricks/lib/python3.7/site-packages/pyspark/")
```

Data that is copied into DB using the cluster web interface, then turned into a
table
```{r write-data}
fs::dir_create("data")
readr::write_csv(nycflights13::flights, "data/flights.csv")
readr::write_csv(iris, "data/iris.csv")
```

If necessary, install Spark
```{r}
# sparklyr::spark_install(version = "2.4.4", hadoop_version = "2.7")
```

```{r spark-connection}
config <- spark_config()
# config$spark.driver.memory = "2g"
# config$sql.catalogImplementation = "hive"
# sc <- spark_connect(master = "local", method = "databricks")
sc <- spark_connect(master = "local", method = "databricks", config = config)
```

```{r}
sc
```

## Copying data
```{r}
cars <- copy_to(sc, mtcars, "cars", overwrite = TRUE)
```

```{r}
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)
```


```{r}
sdf_len(sc, 10) %>% 
  sdf_register("nums")

nums <- tbl(sc, "nums")
nums
```


```{r}
cars <- sdf_copy_to(sc, mtcars, serializer = "csv_string", overwrite = TRUE)
```

```{r}
cars <- sdf_copy_to(sc, mtcars, overwrite = TRUE)
```


```{r}
sparklyr:::spark_connection_in_driver(sc)
```

```{r}
sparklyr:::spark_data_perform_copy(sc, sparklyr:::spark_serialize_csv_string, mtcars, -1)
```


## Connecting to data
```{r spark-data}
flights <- tbl(sc, "flights")
```

```{r}
head(flights)
```

```{r}
flights %>% 
  count(year)
```

## ML in Spark
Taken from: https://spark.rstudio.com/mlib/
```{r}
iris_tbl <- tbl(sc, "iris")
```

```{r}
kmeans_model <- iris_tbl %>% 
  ml_kmeans(Species ~ ., k = 3)
```

```{r}
ml_predict(kmeans_model) %>%
  collect() %>%
  ggplot(aes(Petal_Length, Petal_Width)) +
  geom_point(aes(Petal_Width, Petal_Length, col = factor(prediction + 1)),
             size = 2, alpha = 0.5) + 
  geom_point(data = kmeans_model$centers, aes(Petal_Width, Petal_Length),
             col = scales::muted(c("red", "green", "blue")),
             pch = 'x', size = 12) +
  scale_color_discrete(name = "Predicted Cluster",
                       labels = paste("Cluster", 1:3)) +
  labs(
    x = "Petal Length",
    y = "Petal Width",
    title = "K-Means Clustering",
    subtitle = "Spark overkill"
  )
```


```{r}
lm_model <- iris_tbl %>% 
  select(Petal_Width, Petal_Length) %>% 
  ml_linear_regression(Petal_Length ~ Petal_Width)
```

## Disconnect
```{r}
spark_disconnect(sc)
```

